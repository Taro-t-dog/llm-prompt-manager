"""
æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œã‚¿ãƒ–
"""

import streamlit as st
import datetime
from config import get_model_config
from core import GeminiEvaluator, GitManager
from ui.components import render_response_box, render_evaluation_box, render_cost_metrics


def render_execution_tab():
    """æ”¹å–„ã•ã‚ŒãŸå®Ÿè¡Œã‚¿ãƒ–"""
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
    _initialize_session_state()
    
    # ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªãƒ˜ãƒƒãƒ€ãƒ¼
    exec_col1, exec_col2 = st.columns([3, 1])
    
    with exec_col1:
        st.markdown("### æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ")
    
    with exec_col2:
        current_branch = GitManager.get_current_branch()
        st.markdown(f"**ãƒ–ãƒ©ãƒ³ãƒ:** `{current_branch}`")
    
    # ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦ä¸€æ‹¬å‡¦ç†
    with st.form("execution_form", clear_on_submit=False):
        # å®Ÿè¡Œãƒ¡ãƒ¢
        memo_col1, memo_col2 = st.columns([4, 1])
        
        with memo_col1:
            execution_memo = st.text_input(
                "ğŸ“ å®Ÿè¡Œãƒ¡ãƒ¢",
                value=st.session_state.execution_memo,
                placeholder="å¤‰æ›´å†…å®¹ã‚„å®Ÿé¨“ç›®çš„...",
                key="memo_input_form"
            )
        
        with memo_col2:
            execution_mode = st.radio(
                "ãƒ¢ãƒ¼ãƒ‰",
                ["ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", "å˜ä¸€"],
                index=0 if st.session_state.execution_mode == "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›" else 1,
                horizontal=True,
                key="mode_radio_form"
            )
        
        # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›
        execution_mode_full = "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›" if execution_mode == "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ" else "å˜ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
        prompt_template, user_input_data, single_prompt = _render_prompt_section_form(execution_mode_full)
        
        # è©•ä¾¡åŸºæº–
        evaluation_criteria = _render_evaluation_section_form()
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        submitted = st.form_submit_button("ğŸš€ å®Ÿè¡Œ", type="primary", use_container_width=True)
    
    # ãƒ•ã‚©ãƒ¼ãƒ å¤–ã§å®Ÿè¡Œå‡¦ç†ã¨çµæœè¡¨ç¤º
    if submitted:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’æ›´æ–°
        st.session_state.execution_memo = execution_memo
        st.session_state.execution_mode = execution_mode_full
        st.session_state.evaluation_criteria = evaluation_criteria
        st.session_state.prompt_template = prompt_template
        st.session_state.user_input_data = user_input_data
        st.session_state.single_prompt = single_prompt
        
        # å®Ÿè¡Œå‡¦ç†
        _execute_prompt_direct(execution_memo, execution_mode_full, evaluation_criteria)
    
    # æœ€æ–°ã®å®Ÿè¡Œçµæœã‚’è¡¨ç¤ºï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
    if hasattr(st.session_state, 'latest_execution_result') and st.session_state.latest_execution_result:
        st.markdown("---")
        _display_latest_results()


def _initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    defaults = {
        'execution_memo': "",
        'execution_mode': "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›",
        'prompt_template': "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n\n{user_input}",
        'user_input_data': "",
        'single_prompt': "",
        'evaluation_criteria': """1. æ­£ç¢ºæ€§ï¼ˆ30ç‚¹ï¼‰
2. ç¶²ç¾…æ€§ï¼ˆ25ç‚¹ï¼‰
3. åˆ†ã‹ã‚Šã‚„ã™ã•ï¼ˆ25ç‚¹ï¼‰
4. è«–ç†æ€§ï¼ˆ20ç‚¹ï¼‰"""
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value


def _render_prompt_section_form(execution_mode):
    """ãƒ•ã‚©ãƒ¼ãƒ å†…ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown("### ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    
    if execution_mode == "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›":
        template_col1, template_col2 = st.columns(2)
        
        with template_col1:
            st.markdown("**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**")
            prompt_template = st.text_area(
                "",
                value=st.session_state.prompt_template,
                height=200,
                placeholder="{user_input}ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§",
                key="template_area_form",
                label_visibility="collapsed"
            )
        
        with template_col2:
            st.markdown("**ãƒ‡ãƒ¼ã‚¿**")
            user_input_data = st.text_area(
                "",
                value=st.session_state.user_input_data,
                height=200,
                placeholder="å‡¦ç†ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›...",
                key="data_area_form",
                label_visibility="collapsed"
            )
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if (prompt_template and 
            user_input_data and 
            "{user_input}" in prompt_template):
            
            if st.checkbox("ğŸ” æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª", key="preview_form"):
                final_prompt = prompt_template.replace(
                    "{user_input}", user_input_data
                )
                st.code(final_prompt[:500] + "..." if len(final_prompt) > 500 else final_prompt)
        
        elif prompt_template and "{user_input}" not in prompt_template:
            st.warning("âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«{user_input}ã‚’å«ã‚ã¦ãã ã•ã„")
        
        return prompt_template, user_input_data, ""
    
    else:  # å˜ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        st.markdown("**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**")
        single_prompt = st.text_area(
            "",
            value=st.session_state.single_prompt,
            height=200,
            placeholder="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
            key="single_area_form",
            label_visibility="collapsed"
        )
        return "", "", single_prompt


def _render_evaluation_section_form():
    """ãƒ•ã‚©ãƒ¼ãƒ å†…ã§ã®è©•ä¾¡åŸºæº–è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown("### ğŸ“‹ è©•ä¾¡åŸºæº–")
    evaluation_criteria = st.text_area(
        "",
        value=st.session_state.evaluation_criteria,
        height=120,
        key="criteria_area_form",
        label_visibility="collapsed"
    )
    
    return evaluation_criteria


def _execute_prompt_direct(execution_memo, execution_mode, evaluation_criteria):
    """ç›´æ¥å®Ÿè¡Œå‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ç”¨ï¼‰"""
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    validation_errors = _validate_inputs_direct(execution_memo, execution_mode, evaluation_criteria)
    if validation_errors:
        for error in validation_errors:
            st.error(error)
        return
    
    # APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«è¨­å®š
    if not st.session_state.api_key:
        st.error("âŒ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    model_config = get_model_config(st.session_state.selected_model)
    evaluator = GeminiEvaluator(st.session_state.api_key, model_config)
    
    # æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    if execution_mode == "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›":
        final_prompt = st.session_state.prompt_template.replace(
            "{user_input}", st.session_state.user_input_data
        )
        prompt_template = st.session_state.prompt_template
        user_input = st.session_state.user_input_data
    else:
        final_prompt = st.session_state.single_prompt
        prompt_template = None
        user_input = None
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œ
    with st.spinner(f"ğŸ”„ {model_config['name']}ã§å®Ÿè¡Œä¸­..."):
        execution_result = evaluator.execute_prompt(final_prompt)
    
    if not execution_result['success']:
        st.error(f"âŒ {execution_result['error']}")
        return
    
    # è©•ä¾¡å®Ÿè¡Œ
    with st.spinner("ğŸ“Š è©•ä¾¡ä¸­..."):
        evaluation_result = evaluator.evaluate_response(
            final_prompt,
            execution_result['response'],
            evaluation_criteria
        )
    
    if not evaluation_result['success']:
        st.error(f"âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {evaluation_result['error']}")
        return
    
    # è¨˜éŒ²ä½œæˆã¨ä¿å­˜
    execution_data = {
        'timestamp': datetime.datetime.now(),
        'execution_mode': execution_mode,
        'prompt_template': prompt_template,
        'user_input': user_input,
        'final_prompt': final_prompt,
        'criteria': evaluation_criteria,
        'response': execution_result['response'],
        'evaluation': evaluation_result['response'],
        'execution_tokens': execution_result['total_tokens'],
        'evaluation_tokens': evaluation_result['total_tokens'],
        'execution_cost': execution_result['cost_usd'],
        'evaluation_cost': evaluation_result['cost_usd'],
        'total_cost': execution_result['cost_usd'] + evaluation_result['cost_usd'],
        'model_name': execution_result['model_name'],
        'model_id': execution_result['model_id']
    }
    
    execution_record = GitManager.create_commit(execution_data, execution_memo)
    GitManager.add_commit_to_history(execution_record)
    
    # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    st.session_state.latest_execution_result = {
        'execution_result': execution_result,
        'evaluation_result': evaluation_result,
        'execution_record': execution_record
    }
    
    st.success(f"âœ… å®Ÿè¡Œå®Œäº† | ID: `{execution_record['commit_hash']}`")


def _display_latest_results():
    """æœ€æ–°ã®å®Ÿè¡Œçµæœã‚’è¡¨ç¤º"""
    if not hasattr(st.session_state, 'latest_execution_result') or not st.session_state.latest_execution_result:
        return
    
    result_data = st.session_state.latest_execution_result
    execution_result = result_data['execution_result']
    evaluation_result = result_data['evaluation_result']
    execution_record = result_data['execution_record']
    
    # çµæœè¡¨ç¤º
    result_col1, result_col2 = st.columns([2, 1])
    
    with result_col1:
        render_response_box(execution_result['response'], "ğŸ¤– LLMã®å›ç­”")
        render_evaluation_box(evaluation_result['response'], "â­ è©•ä¾¡çµæœ")
    
    with result_col2:
        st.markdown("### ğŸ“Š å®Ÿè¡Œæƒ…å ±")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        st.metric("å®Ÿè¡Œãƒˆãƒ¼ã‚¯ãƒ³", f"{execution_result['total_tokens']:,}")
        st.metric("è©•ä¾¡ãƒˆãƒ¼ã‚¯ãƒ³", f"{evaluation_result['total_tokens']:,}")
        st.metric("å®Ÿè¡Œã‚³ã‚¹ãƒˆ", f"${execution_result['cost_usd']:.6f}")
        st.metric("è©•ä¾¡ã‚³ã‚¹ãƒˆ", f"${evaluation_result['cost_usd']:.6f}")
        st.metric("ç·ã‚³ã‚¹ãƒˆ", f"${execution_result['cost_usd'] + evaluation_result['cost_usd']:.6f}")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        st.markdown(f"**ãƒ¢ãƒ‡ãƒ«:** {execution_result['model_name']}")
        st.markdown(f"**ãƒ–ãƒ©ãƒ³ãƒ:** {execution_record['branch']}")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèªï¼ˆã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’ä½¿ç”¨ï¼‰
        with st.expander("ğŸ“ å®Ÿè¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª"):
            st.code(execution_record['final_prompt'], language=None)


def _validate_inputs_direct(execution_memo, execution_mode, evaluation_criteria):
    """ç›´æ¥å…¥åŠ›æ¤œè¨¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ç”¨ï¼‰"""
    errors = []
    
    if not execution_memo.strip():
        errors.append("âŒ å®Ÿè¡Œãƒ¡ãƒ¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    if execution_mode == "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ãƒ‡ãƒ¼ã‚¿å…¥åŠ›":
        if not st.session_state.prompt_template.strip():
            errors.append("âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        elif "{user_input}" not in st.session_state.prompt_template:
            errors.append("âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«{user_input}ã‚’å«ã‚ã¦ãã ã•ã„")
        
        if not st.session_state.user_input_data.strip():
            errors.append("âŒ å‡¦ç†ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        if not st.session_state.single_prompt.strip():
            errors.append("âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    if not evaluation_criteria.strip():
        errors.append("âŒ è©•ä¾¡åŸºæº–ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    return errors