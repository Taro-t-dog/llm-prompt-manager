# core/workflow_manager.py (ä¿®æ­£å¾Œ)

import streamlit as st
import uuid
import datetime
import json
from typing import Dict, List, Any, Optional
import yaml
from .workflow_engine import VariableProcessor
from collections import deque
import re

class WorkflowManager:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¿å­˜ã€èª­ã¿è¾¼ã¿ã€æ¤œè¨¼ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def save_workflow(workflow_definition: Dict) -> str:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã™ã‚‹"""
        workflow_id = str(uuid.uuid4())[:12]
        workflow_definition['id'] = workflow_id
        workflow_definition['created_at'] = datetime.datetime.now().isoformat()
        workflow_definition['version'] = '1.1' # Version up
        if 'user_workflows' not in st.session_state:
            st.session_state.user_workflows = {}
        st.session_state.user_workflows[workflow_id] = workflow_definition
        return workflow_id

    @staticmethod
    def get_saved_workflows() -> Dict[str, Dict]:
        """ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å…¨ã¦ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—ã™ã‚‹"""
        return st.session_state.get('user_workflows', {})

    @staticmethod
    def get_workflow(workflow_id: str) -> Optional[Dict]:
        """IDã§ç‰¹å®šã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—ã™ã‚‹"""
        return st.session_state.get('user_workflows', {}).get(workflow_id)

    @staticmethod
    def delete_workflow(workflow_id: str) -> bool:
        """IDã§ç‰¹å®šã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å‰Šé™¤ã™ã‚‹"""
        if workflow_id in st.session_state.get('user_workflows', {}):
            del st.session_state.user_workflows[workflow_id]
            return True
        return False

    @staticmethod
    def duplicate_workflow(workflow_id: str, new_name: str) -> Optional[str]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¤‡è£½ã™ã‚‹"""
        original = WorkflowManager.get_workflow(workflow_id)
        if original:
            new_workflow = original.copy()
            new_workflow['name'] = new_name
            # å†…éƒ¨ã®YAMLå®šç¾©ã®åå‰ã‚‚æ›´æ–°
            if 'source_yaml' in new_workflow and isinstance(new_workflow['source_yaml'], dict):
                new_workflow['source_yaml']['name'] = new_name
                
            for key in ['id', 'created_at', 'version', 'updated_at']:
                new_workflow.pop(key, None)
            return WorkflowManager.save_workflow(new_workflow)
        return None

    @staticmethod
    def update_workflow(workflow_id: str, new_definition: Dict[str, Any]) -> bool:
        """IDã§æŒ‡å®šã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ–°ã—ã„å®šç¾©ã§æ›´æ–°ã™ã‚‹"""
        workflows = WorkflowManager.get_saved_workflows()
        if workflow_id in workflows:
            original_workflow = workflows[workflow_id]
            original_created_at = original_workflow.get('created_at', datetime.datetime.now().isoformat())
            original_version = original_workflow.get('version', '1.0')

            new_definition['id'] = workflow_id
            new_definition['created_at'] = original_created_at
            new_definition['updated_at'] = datetime.datetime.now().isoformat()
            try:
                # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
                new_definition['version'] = f"{float(original_version) + 0.1:.1f}"
            except (ValueError, TypeError):
                new_definition['version'] = '1.1'

            st.session_state.user_workflows[workflow_id] = new_definition
            return True
        return False

    @staticmethod
    def validate_workflow_update(workflow_id: str, new_definition: Dict) -> List[str]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ›´æ–°æ™‚ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã€‚ç¾çŠ¶ã¯æ–°è¦ä½œæˆæ™‚ã¨åŒã˜ã€‚"""
        # æ›´æ–°ç‰¹æœ‰ã®ãƒã‚§ãƒƒã‚¯ã¯ã“ã“ã«å®Ÿè£…ã§ãã‚‹ãŒã€ä»Šã®ã¨ã“ã‚ã¯æ±ç”¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‘¼ã³å‡ºã™
        return WorkflowManager.validate_workflow(new_definition)

    @staticmethod
    def validate_workflow(workflow_definition: Dict) -> List[str]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã®æ§‹é€ ã¨å¤‰æ•°ã®æ•´åˆæ€§ã‚’æ¤œè¨¼ã™ã‚‹"""
        errors = []
        # source_yaml ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆã—ã¦æ¤œè¨¼
        if 'source_yaml' in workflow_definition and isinstance(workflow_definition.get('source_yaml'), dict):
            nodes = workflow_definition['source_yaml'].get('nodes', {})
            if not nodes:
                errors.append("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã« 'nodes' ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                try:
                    WorkflowManager._topological_sort(nodes)
                except ValueError as e:
                    errors.append(str(e))
                # å„ãƒãƒ¼ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã®æ¤œè¨¼
                all_node_ids = set(nodes.keys())
                global_vars = set(workflow_definition.get('global_variables', []))
                for node_id, node_def in nodes.items():
                    dependencies = WorkflowManager._get_node_dependencies(node_def)
                    for dep in dependencies:
                        if dep not in all_node_ids and dep not in global_vars:
                            errors.append(f"ãƒãƒ¼ãƒ‰ '{node_id}' ã«æœªå®šç¾©ã®ä¾å­˜é–¢ä¿‚ãŒã‚ã‚Šã¾ã™: '{dep}'")
            return errors

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (å¤ã„å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ç”¨)
        if 'name' not in workflow_definition or not workflow_definition['name'].strip():
            errors.append("å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ 'name' ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        if 'steps' not in workflow_definition or not isinstance(workflow_definition['steps'], list):
            errors.append("å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ 'steps' ãŒç©ºã‹ã€ãƒªã‚¹ãƒˆå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return errors
        
        for i, step in enumerate(workflow_definition['steps']):
            errors.extend(WorkflowManager._validate_step(step, i + 1))
        
        return errors

    @staticmethod
    def _validate_step(step: Dict, step_number: int) -> List[str]:
        """å€‹åˆ¥ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¤œè¨¼ã™ã‚‹"""
        errors = []
        if not isinstance(step, dict):
            return [f"ã‚¹ãƒ†ãƒƒãƒ— {step_number}: å®šç¾©ãŒè¾æ›¸å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"]
        if 'name' not in step or not step['name'].strip():
            errors.append(f"ã‚¹ãƒ†ãƒƒãƒ— {step_number}: 'name' ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        if 'prompt_template' not in step:
            errors.append(f"ã‚¹ãƒ†ãƒƒãƒ— {step_number}: 'prompt_template' ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return errors
    
    @staticmethod
    def import_from_yaml(yaml_data: str) -> Dict[str, Any]:
        """YAMLã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹"""
        try:
            workflow_data = yaml.safe_load(yaml_data)
            if not isinstance(workflow_data, dict):
                return {'success': False, 'errors': ['YAMLã®ãƒ«ãƒ¼ãƒˆã¯è¾æ›¸å½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚']}
            
            internal_definition, validation_errors = WorkflowManager._parse_yaml_to_internal(workflow_data)
            if validation_errors:
                return {'success': False, 'errors': validation_errors}

            workflow_id = WorkflowManager.save_workflow(internal_definition)
            return {'success': True, 'workflow_id': workflow_id, 'workflow_name': internal_definition.get('name', 'ç„¡å')}

        except yaml.YAMLError as e:
            return {'success': False, 'errors': [f'YAMLè§£æã‚¨ãƒ©ãƒ¼: {e}']}
        except Exception as e:
            return {'success': False, 'errors': [f'ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}']}

    @staticmethod
    def export_to_yaml(workflow_id: str) -> Optional[str]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’YAMLå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹"""
        workflow = WorkflowManager.get_workflow(workflow_id)
        if not workflow:
            return None
        
        yaml_definition = workflow.get('source_yaml')
        if not yaml_definition or not isinstance(yaml_definition, dict):
             st.error("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½ãªYAMLå®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯å¤ã„å½¢å¼ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
             return None

        try:
            return yaml.dump(yaml_definition, allow_unicode=True, sort_keys=False, indent=2)
        except Exception as e:
            st.error(f"YAMLã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    @staticmethod
    def _parse_yaml_to_internal(yaml_def: Dict) -> tuple[Dict, list]:
        """YAMLå®šç¾©ã‚’æ­£è¦åŒ–ã•ã‚ŒãŸå†…éƒ¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
        errors = []
        if 'name' not in yaml_def: errors.append("YAMLã« 'name' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        if 'nodes' not in yaml_def: errors.append("YAMLã« 'nodes' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        if errors: return {}, errors

        try:
            sorted_node_ids = WorkflowManager._topological_sort(yaml_def['nodes'])
        except ValueError as e:
            return {}, [f"ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}"]
        
        internal_steps = [{'name': node_id, 'prompt_template': yaml_def['nodes'][node_id].get('prompt_template', '')} for node_id in sorted_node_ids if yaml_def['nodes'][node_id].get('type') == 'llm']

        internal_def = {
            'name': yaml_def.get('name', 'ç„¡åã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼'),
            'description': yaml_def.get('description', ''),
            'global_variables': yaml_def.get('global_variables', []),
            'steps': internal_steps,
            'source_yaml': yaml_def
        }
        final_errors = WorkflowManager.validate_workflow(internal_def)
        return internal_def, final_errors

    @staticmethod
    def parse_builder_to_internal(name: str, desc: str, steps: List[Dict], g_vars: List[str]) -> Dict:
        """UIãƒ“ãƒ«ãƒ€ãƒ¼ã®æƒ…å ±ã‚’æ­£è¦åŒ–ã•ã‚ŒãŸå†…éƒ¨å½¢å¼ï¼ˆYAMLäº’æ›ï¼‰ã«å¤‰æ›ã™ã‚‹"""
        nodes = {}
        # ğŸ‘ˆ [ä¿®æ­£] ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’é™çš„ãƒãƒ¼ãƒ‰ã¨ã—ã¦è¿½åŠ ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‰Šé™¤ã€‚
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¯å®Ÿè¡Œæ™‚ã« context ã«ç›´æ¥æ³¨å…¥ã•ã‚Œã‚‹ãŸã‚ã€ãƒãƒ¼ãƒ‰ã¨ã—ã¦å®šç¾©ã™ã‚‹å¿…è¦ã¯ãªã„ã€‚

        # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’LLMãƒãƒ¼ãƒ‰ã¨ã—ã¦è¿½åŠ 
        step_names = [s['name'] for s in steps]
        for i, step in enumerate(steps):
            node_id = step.get('name')
            if not node_id: continue # åå‰ãŒãªã„ã‚¹ãƒ†ãƒƒãƒ—ã¯ç„¡è¦–

            prompt_deps = set()
            prompt = step.get('prompt_template', '')
            for var in re.findall(r'\{([^}]+)\}', prompt):
                dep_name = var.split('|')[0].strip().split('.')[0]
                # ä¾å­˜å…ˆãŒä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if dep_name in step_names or dep_name in g_vars:
                     prompt_deps.add(dep_name)

            # UIã§æ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚ŒãŸä¾å­˜é–¢ä¿‚ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸä¾å­˜é–¢ä¿‚ã‚’ãƒãƒ¼ã‚¸
            all_deps = sorted(list(set(step.get('dependencies', [])) | prompt_deps))

            nodes[node_id] = {
                'type': 'llm',
                'agent': 'default', # å°†æ¥çš„ãªæ‹¡å¼µç”¨
                'prompt_template': step.get('prompt_template', ''),
                'inputs': [f":{dep}" for dep in all_deps]
            }
        
        # æœ€å¾Œã®LLMãƒãƒ¼ãƒ‰ã‚’ isResult ã¨ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã¯ç¶­æŒ
        llm_nodes = [s['name'] for s in steps if s.get('name')]
        if llm_nodes:
            llm_node_deps = {nid: set(WorkflowManager._get_node_dependencies(nodes[nid])) for nid in llm_nodes if nid in nodes}
            
            final_candidates = []
            for nid in llm_nodes:
                # è‡ªåˆ†ã«ä¾å­˜ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ãªã„ãƒãƒ¼ãƒ‰ã‚’æ¢ã™
                is_depended_on = any(nid in deps for deps in llm_node_deps.values())
                if not is_depended_on:
                    final_candidates.append(nid)
            
            if final_candidates:
                 # è¤‡æ•°ã®çµ‚ç‚¹ãƒãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€åå‰é †ã§æœ€å¾Œã®ã‚‚ã®ã‚’çµæœã¨ã™ã‚‹
                 nodes[sorted(final_candidates)[-1]]['isResult'] = True
            elif llm_nodes: # å¾ªç’°ãªã©ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµæœã¨ã™ã‚‹
                 nodes[llm_nodes[-1]]['isResult'] = True

        yaml_def = {
            'name': name,
            'description': desc,
            'global_variables': g_vars,
            'nodes': nodes
        }
        
        return {
            'name': name,
            'description': desc,
            'global_variables': g_vars,
            'steps': steps, 
            'source_yaml': yaml_def
        }

    @staticmethod
    def _topological_sort(nodes: Dict) -> List[str]:
        """ãƒãƒ¼ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’è§£æ±ºã—ã€å®Ÿè¡Œé †åºã‚’æ±ºå®šã™ã‚‹"""
        graph, in_degree = {node_id: [] for node_id in nodes}, {node_id: 0 for node_id in nodes}
        all_node_ids = set(nodes.keys())
        for node_id, node_def in nodes.items():
            dependencies = WorkflowManager._get_node_dependencies(node_def)
            for dep_id in dependencies:
                if dep_id in all_node_ids:
                    graph[dep_id].append(node_id)
                    in_degree[node_id] += 1
        
        queue = deque([node_id for node_id, degree in in_degree.items() if degree == 0])
        sorted_order = []
        while queue:
            u = queue.popleft()
            sorted_order.append(u)
            for v in graph.get(u, []):
                in_degree[v] -= 1
                if in_degree[v] == 0: queue.append(v)
        
        if len(sorted_order) == len(nodes):
            return sorted_order
        else:
            unprocessed = {node for node, degree in in_degree.items() if degree > 0}
            raise ValueError(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«å¾ªç’°ä¾å­˜ãŒå­˜åœ¨ã—ã¾ã™ã€‚æœªå‡¦ç†ãƒãƒ¼ãƒ‰: {unprocessed}")

    @staticmethod
    def _get_node_dependencies(node_def: Dict) -> List[str]:
        """ãƒãƒ¼ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’æŠ½å‡ºã™ã‚‹"""
        deps = set()
        inputs = node_def.get('inputs', [])
        sources = inputs if isinstance(inputs, list) else list(inputs.values())
        for source in sources:
             if isinstance(source, str): deps.add(source.lstrip(':'))
        prompt = node_def.get('prompt_template', '')
        for var in re.findall(r'\{([^}]+)\}', prompt): deps.add(var.split('|')[0].strip().split('.')[0])
        return list(deps)