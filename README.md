# 🚀 LLM Prompt Manager

**LLMプロンプトの設計、実験、評価、バージョン管理を加速する統合プラットフォーム**

LLM Prompt Managerは、大規模言語モデル（LLM）を活用する際のプロンプトエンジニアリングを効率化し、その成果を最大化するために開発されたStreamlitアプリケーションです。Google Geminiモデルとの連携を主軸に、単発のプロンプト実行から複雑な多段階ワークフローの構築・実行までをサポートします。


## ✨ 主な機能

LLM Prompt Managerは、プロンプトエンジニアリングのライフサイクル全体をカバーする豊富な機能を提供します。

*   **🤖 プロンプト実行エンジン:**
    *   Google Geminiモデル（Gemini 2.0 Flash）と連携し、プロンプトを即座に実行。
    *   リアルタイムでのトークン数計算とコスト予測により、予算管理をサポート。
    *   実行時のモデルパラメータ（温度、トップPなど）の調整（将来的な拡張）。
*   **🌿 Git風バージョン管理:**
    *   プロンプトの変更や実験結果を「コミット」として記録。
    *   「ブランチ」を作成し、異なるアイデアや改善案を並行して試行可能。
    *   特定のバージョンに「タグ」を付け、重要なマイルストーンをマーク。
    *   全ての変更履歴は追跡可能で、過去のバージョンへのロールバックも容易（将来的な拡張）。
*   **🔄 多段階ワークフロー処理 (NEW!):**
    *   複数のLLM処理ステップを連鎖的に実行するワークフローをGUIで簡単に構築。
    *   前のステップの出力を後続ステップの入力として動的に利用可能（例: `{step_1_output}`）。
    *   複雑なタスク（文書分析→要約→翻訳など）を自動化し、高度なLLMアプリケーションを実現。
    *   ワークフローの保存、再利用、共有が可能。
*   **📊 AIによる自動評価:**
    *   ユーザー定義の評価基準に基づき、LLMの回答品質をAIが自動で評価。
    *   評価結果もバージョン管理され、プロンプト改善の指標として活用。
    *   客観的かつ一貫性のある評価により、迅速なフィードバックループを実現。
*   **💰 詳細なコスト分析:**
    *   実行ごと、ステップごと、ブランチごと、プロジェクト全体でのコストとトークン使用量を可視化。
    *   モデルごとのコスト比較や、コスト効率の高いプロンプト戦略の策定を支援。
*   **🔍 高度な比較ツール:**
    *   異なるプロンプトやモデル、バージョンによる実行結果を並べて比較。
    *   文字レベルでの差分（Diff）表示により、細かな応答の違いを明確に把握。
    *   パフォーマンスメトリクス（実行時間、トークン数、コスト）も同時に比較。
*   **📁 データ管理と連携:**
    *   実行履歴やワークフロー定義をJSONまたはCSV形式でエクスポート。
    *   外部で作成したデータや、他のチームメンバーが共有するデータをインポート。
    *   チーム内でのプロンプト資産の共有と共同作業を促進。
*   **📈 可視化と分析:**
    *   プロジェクト全体の統計情報（総実行数、総コスト、モデル使用頻度など）をダッシュボードで確認。
    *   ブランチの派生構造や、ワークフローのステップ構成を視覚的に表示（将来的な拡張）。

## 🚀 クイックスタート

### 必要環境

*   Python 3.8 以上
*   Google AI Studio で取得した Gemini API キー

### インストールと実行

1.  **リポジトリをクローン:**
    ```bash
    git clone https://github.com/Taro-t-dog/llm-prompt-manager.git
    cd llm-prompt-manager
    ```
2.  **必要なライブラリをインストール:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Streamlitアプリケーションを実行:**
    ```bash
    streamlit run app.py
    ```
    ブラウザで `http://localhost:8501` が自動的に開きます。

### 初期設定

1.  アプリケーションを開いたら、左側のサイドバーにある「設定」セクションを見つけます。
2.  「🔑 API Key」フィールドに、取得したGoogle Gemini APIキーを入力してください。
3.  APIキーが正しく入力されると、プロンプトの実行が可能になります。

## 🛠️ 使い方ガイド

### 1. 実行タブ (🚀)

プロンプトの作成、単発実行、およびワークフロー実行のメイン画面です。

*   **実行モードの選択:**
    *   **📝 単発処理:** 一つのプロンプトを即座に実行し、結果と評価を得ます。
        *   **テンプレートモード:** プロンプト内に `{user_input}` のようなプレースホルダを記述し、「データ」フィールドに入力することで、動的なプロンプト生成が可能です。
        *   **単一モード:** 固定的なプロンプトを直接入力して実行します。
    *   **🔄 ワークフロー処理:** 複数のLLM処理ステップを組み合わせたワークフローを実行します。
*   **プロンプト入力:** 選択したモードに応じてプロンプトやデータを入力します。
*   **評価基準:** 生成された応答をAIが評価するための基準を記述します（例: 正確性、網羅性、明確さなど）。
*   **実行と評価:** 「🚀 実行 & 自動評価」ボタン（単発処理時）または「🚀 ワークフロー実行」ボタンをクリックします。

### 2. 履歴タブ (📋)

過去の全ての実行記録（単発およびワークフローの各ステップ）を閲覧・管理します。

*   **ブランチ選択:** 表示するブランチを切り替えます。
*   **検索とフィルタリング:** 実行メモ、モデル名、プロンプト内容などで履歴を絞り込めます。
*   **詳細表示:** 各実行記録カードの「詳細を表示」で、使用したプロンプト、LLMの応答、AIによる評価結果、コスト情報などを確認できます。

### 3. 比較タブ (🔍)

2つの異なる実行記録を選択し、その結果を詳細に比較します。

*   **比較対象の選択:** 履歴タブと同様のインターフェースで、比較したい2つの実行記録を選択します。
*   **差分表示:** LLMの応答テキストの差異を文字レベルでハイライト表示します。
*   **メトリクス比較:** コスト、トークン数、実行時間などのパフォーマンス指標を並べて比較します。
*   **評価結果比較:** AIによる評価結果も並べて比較できます。

### 4. 分析タブ (📊)

プロジェクト全体の概要や統計情報を可視化します。

*   **ブランチ構造:** 現在のブランチの派生関係や、各ブランチの最新コミットなどを表示します（将来的な拡張）。
*   **統計サマリー:** 総実行回数、総コスト、モデルごとの使用頻度、期間ごとのアクティビティなどをグラフや数値で表示します。
*   **コスト最適化のヒント:** コストの高いプロンプトやモデルを特定し、改善のための情報を提供します（将来的な拡張）。

### ワークフロー機能の活用 (実行タブ内) 🔄

*   **保存済みワークフローの実行:**
    *   「💾 保存済みワークフロー」タブで、過去に作成・保存したワークフローを選択。
    *   必要なグローバル入力変数（例: 分析対象のドキュメント全体など）を入力。
    *   「実行オプション」でキャッシュ利用やデバッグモードを設定可能。
    *   実行すると、各ステップの進捗と結果がリアルタイムで表示されます。
*   **新規ワークフロー作成:**
    *   「🆕 新規ワークフロー作成」タブで、ワークフロー名、説明、グローバル入力変数を定義。
    *   「ステップ設定」で、各処理ステップの名前、プロンプトテンプレート（変数利用可能）を動的に追加・編集。
        *   例: ステップ1のプロンプト「{document_text} を要約してください。」
        *   例: ステップ2のプロンプト「{step_1_output} の要約からキーワードを抽出してください。」
    *   「テスト実行」で作成中のワークフローを試行し、「保存」で定義を永続化。
*   **高度な設定:**
    *   「🔧 高度な設定」タブで、ワークフローエンジンのキャッシュクリアや、ワークフロー定義のJSONエクスポート/インポートが可能です。



